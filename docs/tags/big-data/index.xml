<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>big-data on Blog Test</title>
    <link>https://rava-dosa.github.io/arm/tags/big-data/</link>
    <description>Recent content in big-data on Blog Test</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://rava-dosa.github.io/arm/tags/big-data/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dialogues on apache spark</title>
      <link>https://rava-dosa.github.io/arm/posts/2018-09-7-spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rava-dosa.github.io/arm/posts/2018-09-7-spark/</guid>
      <description>General Architecture {:class=&amp;ldquo;img-responsive&amp;rdquo;}
Before We start It&amp;rsquo;s totally theoritical I have no practical experience in this topic. I want that(practical experience) that&amp;rsquo;s why I am writing this blog ðŸ˜‰ .
Let&amp;rsquo;s start Where we should/&amp;lsquo;nt use Apache spark ? Spark wasnâ€™t made with online transaction processing ( OLTP ) applications in mind (fast, numerous, atomic transactions). Itâ€™s better suited for online analytical processing ( OLAP ): batch jobs and data mining.</description>
    </item>
    
    <item>
      <title>Dialogues on YARN()</title>
      <link>https://rava-dosa.github.io/arm/posts/2018-08-25-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rava-dosa.github.io/arm/posts/2018-08-25-kafka/</guid>
      <description>General Architecture {:class=&amp;ldquo;img-responsive&amp;rdquo;}
Before We start It&amp;rsquo;s totally theoritical I have no practical experience in this topic. I want that(practical experience) that&amp;rsquo;s why I am writing this blog ðŸ˜‰ . I will be copying the whole content from official documentation.
Let&amp;rsquo;s start Kafka has three main components-&amp;gt;  A Producer: The service that emits the source data. A Broker: Kafka acts as an intermediary between the producer and the consumer. It uses the power of API&amp;rsquo;s to get and broadcast data A Consumer: The service that uses the data which the broker will broadcast.</description>
    </item>
    
    <item>
      <title>How to make writing in a file, safe ?</title>
      <link>https://rava-dosa.github.io/arm/posts/2018-08-27-filelock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rava-dosa.github.io/arm/posts/2018-08-27-filelock/</guid>
      <description>General Architecture ![DB1](/img/Screenshot from 2018-08-27 18-09-19.png){:class=&amp;ldquo;img-responsive&amp;rdquo;}
Before We start It&amp;rsquo;s totally theoritical I have no practical experience in this topic. I want that(practical experience) that&amp;rsquo;s why I am writing this blog ðŸ˜‰ . This is an original content.
Let&amp;rsquo;s start Problem Statement -&amp;gt; This is a distributed system. Multiple system is trying to read or write from a file, Now how to make it safe ? . Safe in the sense that how can sys 4 possibly know that sys 1 is writing in the file.</description>
    </item>
    
    <item>
      <title>Monologue on hadoop file system</title>
      <link>https://rava-dosa.github.io/arm/posts/2018-08-11-hdfs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rava-dosa.github.io/arm/posts/2018-08-11-hdfs/</guid>
      <description>Cluster of computers {:class=&amp;ldquo;img-responsive&amp;rdquo;}
Before We start It&amp;rsquo;s totally theoritical I have no practical experience in this topic. I want that(practical experience) that&amp;rsquo;s why I am writing this blog ðŸ˜‰ . And I am totally copying the content of this blog from Hadoop Documentation.
I just googled this &amp;quot; HDFS relaxes a few POSIX requirements to enable streaming access to file system data &amp;quot; You will find tons of link, You can accuse them of plagiarism, Mine as well.</description>
    </item>
    
    <item>
      <title>Monologue on Map Reduce</title>
      <link>https://rava-dosa.github.io/arm/posts/2018-08-18-mapreduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rava-dosa.github.io/arm/posts/2018-08-18-mapreduce/</guid>
      <description>General Architecture {:class=&amp;ldquo;img-responsive&amp;rdquo;}
Before We start It&amp;rsquo;s totally theoritical I have no practical experience in this topic. I want that(practical experience) that&amp;rsquo;s why I am writing this blog ðŸ˜‰ . I am copying content from various sources which I have read and experimented in the last week.
Installation This [link] works totally fine. Except the download link Use this link to download hadoop instead [link] .Few pointers for misery I faced:</description>
    </item>
    
    <item>
      <title>Monologue on Map Reduce</title>
      <link>https://rava-dosa.github.io/arm/posts/2018-08-18-yarn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rava-dosa.github.io/arm/posts/2018-08-18-yarn/</guid>
      <description>General Architecture {:class=&amp;ldquo;img-responsive&amp;rdquo;}
Before We start It&amp;rsquo;s totally theoritical I have no practical experience in this topic. I want that(practical experience) that&amp;rsquo;s why I am writing this blog ðŸ˜‰ . I am copying content from various sources which I have read and experimented in the last week.
Installation This [link] works totally fine. Except the download link Use this link to download hadoop instead [link] .Few pointers for misery I faced:</description>
    </item>
    
    <item>
      <title>Thinking in an map-reduce way</title>
      <link>https://rava-dosa.github.io/arm/posts/2018-08-18-thinkingmapreduce-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rava-dosa.github.io/arm/posts/2018-08-18-thinkingmapreduce-/</guid>
      <description>General Architecture {:class=&amp;ldquo;img-responsive&amp;rdquo;}
Before We start It&amp;rsquo;s totally theoritical I have no practical experience in this topic. I want that(practical experience) that&amp;rsquo;s why I am writing this blog ðŸ˜‰ . I am not copying content from anywhere.
Preprocessing As per however small my perspective is the I think writing mapper and reducer is not the big-deal, What the most most important thing is data preprocessing, that is how you are gonna provide data to the jar file.</description>
    </item>
    
  </channel>
</rss>
